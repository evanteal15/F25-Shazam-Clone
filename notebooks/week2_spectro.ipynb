{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c06b5b6",
   "metadata": {},
   "source": [
    "## Week 2: Spectrograms\n",
    "\n",
    "This week we will be learning how to make a spectrogram from a numpy array representing a sound waveform.\n",
    "\n",
    "How we are able to do this is by using a fourier transforms which we talked about in our session. Let's now start walking through the steps of how to implment a short-time fourier transform which is what we will use for our music recognition algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal as scipy_signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b38ae5",
   "metadata": {},
   "source": [
    "# Discrete fourier transform\n",
    "\n",
    "This is the simplest form of the fouerir transform. \n",
    "Given the DFT formula from the slides, implement this function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cedd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_dft(audio, sr):\n",
    "    \"\"\" \n",
    "    Calculate the dft for the given audio file. \n",
    "    \n",
    "    Transforms audio from the time domain to the frequency domain by calculating\n",
    "    the fourier coefficients for each frequency bins. The value in each bin is the\n",
    "    magnitude of that frequency.\n",
    "    \"\"\"\n",
    "    \n",
    "    N = len(audio)\n",
    "    X = np.zeros(N, dtype = complex)\n",
    "    \n",
    "    # TODO: Implement the discrete fourier transform (DFT)\n",
    "            \n",
    "    # Return the final transformed data\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b313380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_fft(audio, sr):\n",
    "    \"\"\" \n",
    "    Fast Fourier Transform of the audio file.\n",
    "    Uses the Cooley-Turkey formula.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    N = len(audio)\n",
    "    \n",
    "    # Base case: After a sufficient number of splits, use dft\n",
    "    if N <= 32:\n",
    "        return manual_dft(audio, sr)\n",
    "    \n",
    "    # Take advatange of ft symmetry so divide the dft computation into two parts\n",
    "    # This drastically reduces computation time\n",
    "    even = manual_fft(audio[0::2], sr)\n",
    "    odd = manual_fft(audio[1::2], sr)\n",
    "    \n",
    "    # factor for the odd terms\n",
    "    factor = np.exp(-2j * np.pi * np.arange(N) / N)\n",
    "    return np.concatenate([even + factor[:N // 2] * odd, even + factor[N // 2:] * odd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ada75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_window(N):\n",
    "    \"\"\" Generate the Hamming window for the size of our audio file. \"\"\"\n",
    "    nums = np.arange(N)\n",
    "    return .54 - .46 * np.cos((2 * np.pi * nums) / (N - 1))\n",
    "\n",
    "def pad_signal(signal, nperseg):\n",
    "    \"\"\" Pad the audio to the correct length. \"\"\"\n",
    "    \n",
    "    # sl = len(signal)\n",
    "    \n",
    "    pl = nperseg // 2\n",
    "    \n",
    "    return np.concatenate([np.zeros(pl), signal, np.zeros(pl)])\n",
    "\n",
    "\n",
    "# we will use the discrete forier transform formula since in\n",
    "# digital audio files, audio is stored in discrete packets for \n",
    "# each timestep.\n",
    "def manual_stft(audio, sr):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    audio: NP-Array cntain the amplitude over time for this file\n",
    "    sr (Sampling rate): int for the rate \n",
    "    \n",
    "    Ooutput:\n",
    "    frequencies:\n",
    "    \"\"\"\n",
    "    nperseg = 1024\n",
    "    hop_length = nperseg + (nperseg // 2)\n",
    "    \n",
    "    noverlap = nperseg - hop_length\n",
    "    \n",
    "    N = len(audio)\n",
    "    # output array\n",
    "    X = np.zeros(N, dtype=complex)\n",
    "    \n",
    "    # pad the audio file\n",
    "    ap = pad_signal(audio, nperseg)\n",
    "    \n",
    "    \n",
    "    # create the hamming window for this audio file\n",
    "    windower = hamming_window(nperseg)\n",
    "    \n",
    "    # window_norm = np.sqrt(np.sum(windower**2))\n",
    "    \n",
    "    # get the total size of our padded audio\n",
    "    sl = len(ap)\n",
    "    \n",
    "    # number of complete windows we can fit\n",
    "    num_segs = (sl - nperseg) // hop_length + 1\n",
    "    \n",
    "    # only keep positive frequencies\n",
    "    freq_bins = nperseg // 2 + 1\n",
    "    \n",
    "    stft_matrix = np.zeros((freq_bins, num_segs), dtype = complex)\n",
    "    \n",
    "    # STFT algorith,\n",
    "    for i in range(num_segs):\n",
    "        start = i * hop_length\n",
    "        end = start + nperseg\n",
    "        \n",
    "        if end > sl:\n",
    "            # edge case where our index is longer than our audio file - logic error\n",
    "            break\n",
    "        \n",
    "        # get the windowed section of the audio file\n",
    "        segment = ap[start:end]\n",
    "        windowed_segment = segment * windower\n",
    "        \n",
    "        # calculate the fft of this segment\n",
    "        fft_result = manual_fft(windowed_segment, sr)\n",
    "        \n",
    "        # normalize the result by the sampling rate\n",
    "        fft_result /= (sr)\n",
    "        \n",
    "        # apply Nyquist function\n",
    "        stft_matrix[0, i] = fft_result[0]\n",
    "        stft_matrix[1:-1, i] = fft_result[1:nperseg//2] * 2  # Scale others by 2\n",
    "        stft_matrix[-1, i] = fft_result[nperseg//2]\n",
    "        \n",
    "    # get each frequency bin\n",
    "    frequencies = np.linspace(0, sr / 2, freq_bins)\n",
    "        \n",
    "    # account for the pad in our time calculation\n",
    "    offset = -nperseg / 2 / sr\n",
    "        \n",
    "    # get the timesteps for each measurement\n",
    "    times = np.arange(num_segs) * hop_length / sr + nperseg / 2 / sr + offset\n",
    "    \n",
    "    # return the frequency bins, time stamps, and frequency/maginitude measurements\n",
    "    return frequencies, times, stft_matrix\n",
    "    \n",
    "\n",
    "def compare_with_scipy(audio, fs, nperseg=1024, noverlap=None):\n",
    "    \"\"\"\n",
    "    Compare manual implementation with SciPy's STFT\n",
    "    \"\"\"\n",
    "    if noverlap is None:\n",
    "        noverlap = nperseg - (nperseg // 4)  # 75% overlap\n",
    "        \n",
    "    nperseg = 1024\n",
    "    hop_length = nperseg + (nperseg // 2)\n",
    "    \n",
    "    \n",
    "    print(f\"STFT Parameters:\")\n",
    "    print(f\"  nperseg: {nperseg}\")\n",
    "    print(f\"  noverlap: {noverlap}\")\n",
    "    print(f\"  hop_length: {hop_length}\")\n",
    "    print(f\"  fs: {fs}\")\n",
    "    \n",
    "    # Manual implementation\n",
    "    freq_manual, time_manual, stft_manual = manual_stft(audio, fs)\n",
    "    \n",
    "    # SciPy implementation for comparison\n",
    "    freq_scipy, time_scipy, stft_scipy = scipy_signal.stft(\n",
    "        audio, fs=fs, window=\"hamming\", nperseg=nperseg, noverlap=nperseg - hop_length,\n",
    "        padded=True, return_onesided=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nResults comparison:\")\n",
    "    print(f\"Manual - Frequencies shape: {freq_manual.shape}, Times shape: {time_manual.shape}\")\n",
    "    print(f\"Manual - STFT shape: {stft_manual.shape}\")\n",
    "    print(f\"SciPy  - Frequencies shape: {freq_scipy.shape}, Times shape: {time_scipy.shape}\")\n",
    "    print(f\"SciPy  - STFT shape: {stft_scipy.shape}\")\n",
    "    \n",
    "    # Calculate difference\n",
    "    if stft_manual.shape == stft_scipy.shape:\n",
    "        diff = np.abs(stft_manual - stft_scipy)\n",
    "        max_diff = np.max(diff)\n",
    "        mean_diff = np.mean(diff)\n",
    "        print(f\"Max difference in STFT: {max_diff:.2e}\")\n",
    "        print(f\"Mean difference in STFT: {mean_diff:.2e}\")\n",
    "    \n",
    "    return (freq_manual, time_manual, stft_manual), (freq_scipy, time_scipy, stft_scipy)\n",
    "\n",
    "def plot_stft_comparison(audio, fs, nperseg=1024):\n",
    "    \"\"\"\n",
    "    Plot STFT spectrograms for comparison\n",
    "    \"\"\"\n",
    "    (freq_manual, time_manual, stft_manual), (freq_scipy, time_scipy, stft_scipy) = \\\n",
    "        compare_with_scipy(audio, fs, nperseg)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Manual implementation spectrogram\n",
    "    stft_db_manual = 20 * np.log10(np.abs(stft_manual) + 1e-10)\n",
    "    im1 = axes[0,0].imshow(stft_db_manual, aspect='auto', origin='lower',\n",
    "                          extent=[time_manual[0], time_manual[-1], \n",
    "                                 freq_manual[0], freq_manual[-1]])\n",
    "    axes[0,0].set_title('Manual STFT Implementation')\n",
    "    axes[0,0].set_xlabel('Time (s)')\n",
    "    axes[0,0].set_ylabel('Frequency (Hz)')\n",
    "    plt.colorbar(im1, ax=axes[0,0], label='Magnitude (dB)')\n",
    "    \n",
    "    # SciPy implementation spectrogram\n",
    "    stft_db_scipy = 20 * np.log10(np.abs(stft_scipy) + 1e-10)\n",
    "    im2 = axes[0,1].imshow(stft_db_scipy, aspect='auto', origin='lower',\n",
    "                          extent=[time_scipy[0], time_scipy[-1], \n",
    "                                 freq_scipy[0], freq_scipy[-1]])\n",
    "    axes[0,1].set_title('SciPy STFT Implementation')\n",
    "    axes[0,1].set_xlabel('Time (s)')\n",
    "    axes[0,1].set_ylabel('Frequency (Hz)')\n",
    "    plt.colorbar(im2, ax=axes[0,1], label='Magnitude (dB)')\n",
    "    \n",
    "    # Difference plot\n",
    "    if stft_manual.shape == stft_scipy.shape:\n",
    "        diff_db = 20 * np.log10(np.abs(stft_manual - stft_scipy) + 1e-10)\n",
    "        im3 = axes[1,0].imshow(diff_db, aspect='auto', origin='lower',\n",
    "                              extent=[time_manual[0], time_manual[-1], \n",
    "                                     freq_manual[0], freq_manual[-1]])\n",
    "        axes[1,0].set_title('Difference (Manual - SciPy)')\n",
    "        axes[1,0].set_xlabel('Time (s)')\n",
    "        axes[1,0].set_ylabel('Frequency (Hz)')\n",
    "        plt.colorbar(im3, ax=axes[1,0], label='Difference (dB)')\n",
    "    \n",
    "    # Original signal\n",
    "    t_signal = np.arange(len(audio)) / fs\n",
    "    axes[1,1].plot(t_signal, audio)\n",
    "    axes[1,1].set_title('Original Audio Signal')\n",
    "    axes[1,1].set_xlabel('Time (s)')\n",
    "    axes[1,1].set_ylabel('Amplitude')\n",
    "    axes[1,1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3724a768",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Lets test our manual stft to scipy! We will create a dummy frequency and visualize the spectrogram created by our implementation to the scipy version. Do the visualizaitons appear to be similar (its ok if it is not exact)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01e48d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test signal\n",
    "# Create test signal\n",
    "sr = 1000  # Sample rate\n",
    "duration = 2\n",
    "t = np.linspace(0, duration, int(sr * duration), endpoint=False)\n",
    "\n",
    "# Multi-frequency signal\n",
    "signal_test = (np.sin(2 * np.pi * 50 * t) +        # 50 Hz\n",
    "                0.5 * np.sin(2 * np.pi * 120 * t) +  # 120 Hz\n",
    "                0.3 * np.sin(2 * np.pi * 200 * t))   # 200 Hz\n",
    "\n",
    "# Add some time-varying component\n",
    "signal_test += 0.2 * np.sin(2 * np.pi * (300 + 100 * t) * t)  # Frequency sweep\n",
    "\n",
    "plot_stft_comparison(signal_test, sr)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
