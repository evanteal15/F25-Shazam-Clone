{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4c9acb8",
   "metadata": {},
   "source": [
    "# Intro to Digital Audio\n",
    "\n",
    "To be able to work with audio signals in a computer, we need to create a series of discrete values from a continuous sound wave.\n",
    "\n",
    "This notebook will walk you through the fundamentals of how audio is represented in Python, how to create a custom dataset of music using yt-dlp/musicdl, and how to visualize the waveform of an audio file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a92e900",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/MichiganDataScienceTeam/F25-Shazam/blob/main/notebooks/week1_audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574769f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas numpy matplotlib librosa scipy yt-dlp pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd4cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ffeaa",
   "metadata": {},
   "source": [
    "\n",
    "## What is a sound wave?\n",
    "\n",
    "A sound wave is created by the vibration of air molecules.\n",
    "\n",
    "\n",
    "- **frequency**: number of times that air particles vibrate back and forth per second (Hz). \n",
    "    - This is perceived by us as the pitch\n",
    "- **amplitude**: maximum distance that air particles are displaced (from rest) as the sound wave passes\n",
    "    - This is perceived by us as the loudness, measured in decibels (dB)\n",
    "\n",
    "We perceive frequency and amplitude **logarithmically**; as frequency or amplitude increases, it takes more of a change in the respective quantity to produce the same percieved change in pitch/loudness.\n",
    "\n",
    "![metadata](./asset/sample_metadata.png)\n",
    "\n",
    "Let's break down some common aspects of an audio file:\n",
    "\n",
    "- **sample rate** - number of samples per second (Hz). The sampling rate determines the time resolution of our representation.\n",
    "    - Time is digitized using the sample rate\n",
    "    - The time in seconds between consecutive samples is $1/\\mathrm{sr}$, called the sampling interval\n",
    "- **bit depth** - The number of bits used to store each sample. The larger the bit depth, the more precision we have to store amplitude information (amplitude resolution).\n",
    "    - Amplitude is digitized using bit depth\n",
    "    \n",
    "<br>\n",
    "\n",
    "When working with MP3 files, another useful piece of information is the bit rate - the data transfer rate expressed as bits per second.\n",
    "- $\\mathrm{bit\\ depth} \\neq \\mathrm{bit\\ rate}$\n",
    "- $\\mathrm{bit\\ rate} = \\mathrm{sr}\\times\\mathrm{bit\\ depth}\\times\\textrm{number\\ of\\ channels}$\n",
    "- mp3 files lose bit depth information during the lossy compression process\n",
    "\n",
    "## Digital Waveform Representation\n",
    "\n",
    "![waveform](./asset/digital_waveform.jpg)\n",
    "\n",
    "Modify the code below to try out different values of `freq_Hz` and `sample_rate_Hz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ce5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency of the audio signal\n",
    "freq_Hz = 5\n",
    "\n",
    "# rate at which the audio signal is being sampled\n",
    "sample_rate_Hz = 10\n",
    "\n",
    "x_source = np.linspace(0, 1, 1000, endpoint=False)\n",
    "y_source = np.cos(freq_Hz * 2*np.pi*x_source)\n",
    "\n",
    "x_samples = np.linspace(0, 1, sample_rate_Hz, endpoint=False)\n",
    "y_samples = np.cos(freq_Hz * 2*np.pi*x_samples)\n",
    "\n",
    "plt.plot(x_source, y_source)\n",
    "plt.scatter(x_samples, y_samples, color=\"red\", s=50)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f3c2bb",
   "metadata": {},
   "source": [
    "## How many samples do we need?\n",
    "\n",
    "The samples inside a wav file are used to reconstruct the original audio as a continuous waveform to be played back for listening.\n",
    "\n",
    "**Nyquist-Shannon sampling theorem**: If a signal contains no frequencies higher than $f_\\mathrm{max}$, then the signal can be perfectly reconstructed when sampled at a rate $sr > 2f_\\mathrm{max}$. In other words, the maximum reconstructable frequency is strictly less than $sr/2$.\n",
    "\n",
    "When there is a frequency higher than $sr/2$ in the signal, the frequency instead appears in the reconstructed signal at a lower frequency than the original. This effect is called **aliasing**, and is usually undesirable.\n",
    "\n",
    "**Question**: In order to cover the human hearing range of 20 Hz to 20 kHz, what is the minimum sampling rate required?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711b5144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling_rate_required = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7ac3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate_Hz = 5\n",
    "freq_Hz = 7\n",
    "\n",
    "# The Nyquist frequency is defined as sr/2\n",
    "# Any sinusoid with freq > sr/2 has an alias with freq < sr/2\n",
    "#     alias: sinusoid indistinguisable by sampling alone (same samples)\n",
    "k: int = 1  # any integer\n",
    "freq_alias_wave_Hz = np.abs(freq_Hz - k*sample_rate_Hz)\n",
    "\n",
    "x_source = np.linspace(0, 1, 1000, endpoint=False)\n",
    "y_source = np.cos(freq_Hz * 2*np.pi*x_source)\n",
    "\n",
    "x_reconstructed = np.linspace(0, 1, 1000, endpoint=False)\n",
    "y_reconstructed = np.cos(min(freq_alias_wave_Hz, freq_Hz) * 2*np.pi*x_reconstructed)\n",
    "\n",
    "x_samples = np.linspace(0, 1, sample_rate_Hz, endpoint=False)\n",
    "y_samples = np.cos(freq_Hz * 2*np.pi*x_samples)\n",
    "\n",
    "plt.plot(x_source, y_source)\n",
    "plt.plot(x_reconstructed, y_reconstructed, color=\"red\", linestyle=\"--\")\n",
    "plt.scatter(x_samples, y_samples, color=\"red\", s=50)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61deb37b",
   "metadata": {},
   "source": [
    "## Data collection\n",
    "\n",
    "To create a database of songs that our Shazam clone will be able to recognize, we can use the [yt-dlp](https://github.com/yt-dlp/yt-dlp) Python package to download audio files directly from YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97125266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "\n",
    "# add any youtube video url here, \n",
    "# copied from browser address bar\n",
    "youtube_url = \"\"\n",
    "\n",
    "yt_audio_path = \"yt_sample.wav\"\n",
    "\n",
    "ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': \"yt_sample.%(ext)s\",  # output file\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'wav',     # save as wav file\n",
    "        }],\n",
    "        #'cookiefile': 'cookies.txt',\n",
    "    }\n",
    "if youtube_url != \"\":\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([youtube_url])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d34d356",
   "metadata": {},
   "source": [
    "## musicdl: helper script for downloading audio\n",
    "\n",
    "For convienience, we've created a yt-dlp wrapper program that accepts urls from either YouTube or Spotify, and downloads the respective audio files to a specified folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2becfb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --depth 1 https://github.com/dennisfarmer/musicdl.git\n",
    "%pip install -e ./musicdl\n",
    "from musicdl.yt import YoutubeDownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b074ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(YoutubeDownloader.download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072d2b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "ydl = YoutubeDownloader(\n",
    "    audio_directory=\"./tracks\", \n",
    "    audio_format=\"wav\"\n",
    ")\n",
    "\n",
    "youtube_urls = [\n",
    "    \"https://www.youtube.com/watch?v=TqxfdNm4gZQ\"\n",
    "]\n",
    "\n",
    "tracks_info = ydl.download(youtube_urls)\n",
    "pprint(tracks_info)\n",
    "\n",
    "# write to csv\n",
    "tracks_csv = \"./tracks/tracks_info.csv\"\n",
    "tracks_df = pd.DataFrame(tracks_info)\n",
    "tracks_df.to_csv(tracks_csv, index=False)\n",
    "\n",
    "# read from csv\n",
    "#with open(tracks_csv, \"r\") as f:\n",
    "    #tracks_df = pd.read_csv(f)\n",
    "    #tracks_list = list(tracks_df.to_dict(orient=\"records\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0884c",
   "metadata": {},
   "source": [
    "## Visualizing the amplitude and sample rate of an audio file\n",
    "\n",
    "[`librosa.load()` documentation](https://librosa.org/doc/0.11.0/generated/librosa.load.html#librosa.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac27996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "#audio_path = yt_audio_path\n",
    "audio_path = \"sample.wav\"\n",
    "ipd.Audio(audio_path)\n",
    "\n",
    "# Use librosa.load() to read file at audio_path\n",
    "# default is to convert to mono (1 channel)\n",
    "# audio, sr = ???\n",
    "#print(f\"sample rate = {sr} Hz\")\n",
    "\n",
    "#plt.figure(figsize=(12, 4))\n",
    "#plt.plot(audio, lw=0.1)  # interpolated waveform\n",
    "#plt.scatter(np.arange(len(audio)), audio, s=0.005, color=\"red\")  # individual samples\n",
    "#plt.title(\"Audio Waveform\")\n",
    "#plt.xlabel(\"Sample Index\")\n",
    "#plt.ylabel(\"Amplitude\")\n",
    "#plt.show()\n",
    "\n",
    "#print(\"audio is digitally represented as a numpy.ndarray:\")\n",
    "#audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e8a67",
   "metadata": {},
   "source": [
    "## Downsampling\n",
    "\n",
    "internally, downsampling (reducing the sample rate) performs the following process:\n",
    "1. uses a low pass anti-aliasing filter to remove higher frequency components\n",
    "    - low pass: keep signals with frequency lower than a specified cutoff frequency\n",
    "2. keeps every nth sample using a sample step size of $(\\mathrm{sr_{old}}/\\mathrm{sr_{new}})$\n",
    "    - the details of this process are not super important to know\n",
    "    - if $(\\mathrm{sr_{old}}/\\mathrm{sr_{new}})$ is not an integer, first upsamples via interpolation, then downsamples with step size $\\mathrm{sr_{old}}$.\n",
    "    - upsampling: each original sample is separated by inserting $(\\mathrm{sr_{new}}-1)$ zeros, then signal is interpolated with filter to smooth out discontinuities (replacing zeros)\n",
    "\n",
    "**Question**: In the low pass filter step, what would the cutoff frequency be if we resampled to 11,025 Hz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4f7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutoff_frequency = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d5ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample from 48,000 Hz to 11,025 Hz\n",
    "# use librosa.load()\n",
    "sr = 11_025\n",
    "\n",
    "# Question: how would you plot just the first 10 seconds of an audio file?\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653caec9",
   "metadata": {},
   "source": [
    "# Task for today:\n",
    "\n",
    "1) download the audio from any youtube video as a .wav file\n",
    "2) downsample the file to 44.1 kHz\n",
    "3) crop the audio to any 5 second segment\n",
    "4) visualize the waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faae90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea22f463",
   "metadata": {},
   "source": [
    "---\n",
    "**BONUS**: Add noise to an audio\n",
    "- brownian noise: $x(n+1) = x(n) + w(n)$\n",
    "- $w(n) \\stackrel{\\mathrm{iid}}{\\sim} \\mathrm{N(0,1)}$\n",
    "- $\\mathtt{np.random.normal(0, 1, n), np.cumsum()}$\n",
    "\n",
    "Why might this be useful for a music recognition system?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be719ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS: add noise to a file\n",
    "# brownian noise: x(n+1) = x(n) + w(n)\n",
    "#                 w(n) = N(0,1)\n",
    "\n",
    "audio, sr = librosa.load(audio_path, sr=None) \n",
    "noise = np.zeros(audio.shape[0])\n",
    "\n",
    "def peak_normalize(x):\n",
    "    # Normalize the audio to be within the range [-1, 1]\n",
    "    return x / np.max(np.abs(x))\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# 16-bit integer: [-32768, 32767]\n",
    "# (2**15 - 1) = 32767\n",
    "audio_with_noise = (audio + noise*0.5)\n",
    "scaled = np.int16(peak_normalize(audio_with_noise) * 32767)\n",
    "scipy.io.wavfile.write('audio_with_noise.wav', sr, scaled)\n",
    "ipd.Audio(\"audio_with_noise.wav\")\n",
    "\n",
    "# YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
