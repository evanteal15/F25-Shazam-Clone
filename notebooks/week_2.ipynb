{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8034c72d",
   "metadata": {},
   "source": [
    "# Next week: visualizing frequency using a spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d521e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import scipy\n",
    "import IPython.display as ipd\n",
    "\n",
    "audio_path = \"asset/log_scale_perception.wav\"\n",
    "ipd.Audio(audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea477653",
   "metadata": {},
   "source": [
    "## Method 1: Librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a3acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, sr = librosa.load(audio_path, sr=None) \n",
    "\n",
    "# parameters of the short-time Fourier transform:\n",
    "# (algorithm that creates the spectrogram)\n",
    "win_length = 2**11  # number of samples in each window\n",
    "n_fft = win_length\n",
    "hop_length = win_length // 4\n",
    "window = scipy.signal.get_window(\"triang\", Nx=win_length)\n",
    "\n",
    "S = librosa.stft(audio, \n",
    "                       n_fft=n_fft, hop_length=hop_length, \n",
    "                       win_length=win_length, window=window)\n",
    "S_magnitude = np.abs(S)  # |a+bi| = sqrt(a^2 + b^2)\n",
    "S_db = librosa.amplitude_to_db(S_magnitude, ref=np.max)\n",
    "\n",
    "im = plt.imshow(S_db, cmap=\"inferno\", aspect=\"auto\", origin=\"lower\")\n",
    "plt.colorbar(im, format=\"%+2.0f dB\")\n",
    "plt.xlabel(\"Time (sec)\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc47201",
   "metadata": {},
   "source": [
    "## Method 2: Scipy (what we'll use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd19504",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, sr = librosa.load(audio_path, sr=None) \n",
    "\n",
    "# parameters of the short-time Fourier transform:\n",
    "# (algorithm that creates the spectrogram)\n",
    "nperseg = win_length = 2**11  # number of samples in each window\n",
    "nfft = n_fft = win_length\n",
    "hop_length = win_length // 4\n",
    "window = scipy.signal.get_window(\"triang\", Nx=win_length)\n",
    "\n",
    "# scipy.signal.stft also uses the sample rate to output \n",
    "# frequency (in Hz) and time (in seconds) vectors,\n",
    "# corresponding to the rows and columns of the stft matrix \n",
    "# in \"s_scipy\"\n",
    "fs=sr \n",
    "noverlap = nperseg - hop_length\n",
    "\n",
    "freq_scipy, time_scipy, s_scipy = scipy.signal.stft(\n",
    "    audio, \n",
    "    fs=fs, window=\"hann\", nfft=nfft, \n",
    "    nperseg=nperseg, noverlap=noverlap\n",
    ")\n",
    "\n",
    "print(f\"freq vector shape: {freq_scipy.shape}\")\n",
    "print(f\"time vector shape: {time_scipy.shape}\")\n",
    "print(f\"stft matrix shape: {s_scipy.shape}\")\n",
    "\n",
    "s_scipy_db = librosa.amplitude_to_db(np.abs(s_scipy), ref=np.max)\n",
    "\n",
    "im = plt.imshow(s_scipy_db, cmap=\"inferno\", aspect=\"auto\", origin=\"lower\")\n",
    "plt.colorbar(im, format=\"%+2.0f dB\")\n",
    "plt.xlabel(\"Time (sec)\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a8c49c",
   "metadata": {},
   "source": [
    "## Recording from Microphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29877fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.io.wavfile\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "\n",
    "def record_audio(n_seconds: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Record audio using computer microphone.\n",
    "    \"\"\"\n",
    "    chunk = 1024\n",
    "    bit_depth = pyaudio.paInt16\n",
    "    n_channels = 1\n",
    "    sample_rate = 48000\n",
    "\n",
    "    input(\"Press Enter to begin recording ðŸŽ¤\")\n",
    "    print(\"ðŸŽ¤ Listening for music\", end=\"\\r\")\n",
    "\n",
    "    outfile = \"microphone_sample.wav\"\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=bit_depth, channels=n_channels, rate=sample_rate, input=True, frames_per_buffer=chunk)\n",
    "\n",
    "    frames = []\n",
    "    for _ in range(0, int(sample_rate / chunk * n_seconds)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "\n",
    "    audio_np = np.frombuffer(b''.join(frames), dtype=np.int16)\n",
    "    scipy.io.wavfile.write(outfile, sample_rate, audio_np)\n",
    "    print(f\"âœ… Recording saved to {outfile}\", end=\"\\n\")\n",
    "\n",
    "    return outfile\n",
    "\n",
    "#audio_path = record_audio()\n",
    "\n",
    "#audio_path = \"microphone_sample.wav\"\n",
    "\n",
    "audio, sr = librosa.load(audio_path, sr=None) \n",
    "S_db = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
    "im = plt.imshow(S_db, cmap=\"inferno\", aspect=\"auto\", origin=\"lower\")\n",
    "plt.colorbar(im, format=\"%+2.0f dB\")\n",
    "plt.xlabel(\"Time (sec)\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
